{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w_z3ezz-IMpA"
   },
   "outputs": [],
   "source": [
    "# Run this block once to install these libs\n",
    "\n",
    "# !pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
    "# !pip install scipy==1.2.1\n",
    "# !pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1686,
     "status": "ok",
     "timestamp": 1588410474891,
     "user": {
      "displayName": "Maria Mahbub",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQyYlcc7Ts8pou2N_rxNtZawQminV0SA-tjYzK=s64",
      "userId": "18117529587993011390"
     },
     "user_tz": 240
    },
    "id": "ocoQEhQmZo6h",
    "outputId": "4744af47-63d7-4b3a-b65d-0c244592759c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n",
      "1.15.2\n",
      "2.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m pip install tensorflow==1.13.1\n",
    "# tensorflow==1.13.1\n",
    "# keras==2.2.4\n",
    "# !pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
    "\n",
    "%tensorflow_version 1.x\n",
    "\n",
    "import tensorflow\n",
    "import keras\n",
    "print(tensorflow.__version__)\n",
    "print(keras.__version__)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1588410479303,
     "user": {
      "displayName": "Maria Mahbub",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQyYlcc7Ts8pou2N_rxNtZawQminV0SA-tjYzK=s64",
      "userId": "18117529587993011390"
     },
     "user_tz": 240
    },
    "id": "4qXPvxzNZv5V",
    "outputId": "0ad28214-6c1f-49be-d434-b39f1640fdc3"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SjLOXvcDZv7a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 552,
     "status": "ok",
     "timestamp": 1588410481314,
     "user": {
      "displayName": "Maria Mahbub",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQyYlcc7Ts8pou2N_rxNtZawQminV0SA-tjYzK=s64",
      "userId": "18117529587993011390"
     },
     "user_tz": 240
    },
    "id": "22GV37958mGO",
    "outputId": "574521aa-7d46-4c25-b637-03e384d08e33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n",
      "['trainB_', 'trainA_', 'trainA', 'trainB']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "print(tf.test.gpu_device_name())\n",
    "\n",
    "base_path = os.path.abspath(\"../\")\n",
    "# '/content/gdrive/My Drive/adversarial-xray'\n",
    "\n",
    "dataset_path = os.path.join(base_path, \"dataset/dataGAN\")\n",
    "model_path = os.path.join(base_path, \"models_p\")\n",
    "print(os.listdir(dataset_path))\n",
    "\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, dataset_name, img_res=(256, 256)): \n",
    "        self.dataset_name = dataset_name\n",
    "        self.img_res = img_res\n",
    "\n",
    "    def load_data(self, domain, batch_size=1, is_testing=False):\n",
    "        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
    "        path = glob('{}/dataset/%s/%s/*'.format(base_path) % (self.dataset_name, data_type))\n",
    "\n",
    "        batch_images = np.random.choice(path, size=batch_size)\n",
    "\n",
    "        imgs = []\n",
    "        for img_path in batch_images:\n",
    "            img = self.imread(img_path)\n",
    "            if not is_testing:\n",
    "                img = scipy.misc.imresize(img, self.img_res)\n",
    "\n",
    "                if np.random.random() > 0.5:\n",
    "                    img = np.fliplr(img)\n",
    "            else:\n",
    "                img = scipy.misc.imresize(img, self.img_res)\n",
    "            imgs.append(img)\n",
    "\n",
    "        # rescale to [-1, 1]\n",
    "        imgs = np.array(imgs)/127.5 - 1.\n",
    "        \n",
    "        return imgs\n",
    "\n",
    "    def load_batch(self, batch_size=1, is_testing=False):\n",
    "        data_type = \"train\" if not is_testing else \"val\"\n",
    "        path_A = glob('{}/dataset/%s/%sA_/*'.format(base_path) % (self.dataset_name, data_type))\n",
    "        path_B = glob('{}/dataset/%s/%sB_/*'.format(base_path) % (self.dataset_name, data_type))\n",
    "\n",
    "        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n",
    "        total_samples = self.n_batches * batch_size\n",
    "\n",
    "        # Sample n_batches * batch_size from each path list \n",
    "        path_A = np.random.choice(path_A, total_samples, replace=False)\n",
    "        path_B = np.random.choice(path_B, total_samples, replace=False)\n",
    "\n",
    "        for i in range(self.n_batches-1):\n",
    "            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n",
    "            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n",
    "            imgs_A, imgs_B = [], []\n",
    "            for img_A, img_B in zip(batch_A, batch_B):\n",
    "                img_A = self.imread(img_A)\n",
    "                img_B = self.imread(img_B)\n",
    "\n",
    "                img_A = scipy.misc.imresize(img_A, self.img_res)\n",
    "                img_B = scipy.misc.imresize(img_B, self.img_res)\n",
    "\n",
    "                if not is_testing and np.random.random() > 0.5:\n",
    "                        img_A = np.fliplr(img_A)\n",
    "                        img_B = np.fliplr(img_B)\n",
    "\n",
    "                imgs_A.append(img_A)\n",
    "                imgs_B.append(img_B)\n",
    "\n",
    "            # rescale to [-1, 1]\n",
    "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
    "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
    "            \n",
    "            yield imgs_A, imgs_B\n",
    "\n",
    "    def load_img(self, path):\n",
    "        img = self.imread(path)\n",
    "        img = scipy.misc.imresize(img, self.img_res)\n",
    "        \n",
    "        # rescale to [-1, 1]\n",
    "        img = img/127.5 - 1.\n",
    "        \n",
    "        return img[np.newaxis, :, :, :]\n",
    "\n",
    "    def imread(self, path):\n",
    "        return scipy.misc.imread(path, mode='RGB').astype(np.float) # np.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1588410483822,
     "user": {
      "displayName": "Maria Mahbub",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQyYlcc7Ts8pou2N_rxNtZawQminV0SA-tjYzK=s64",
      "userId": "18117529587993011390"
     },
     "user_tz": 240
    },
    "id": "2T6J9i-EF3-C",
    "outputId": "3bcd978f-51b2-4913-b0d9-d50228caf766"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/content/gdrive/My Drive/adversarial-xray/dataset/dataGAN/trainB_/12.jpeg',\n",
       " '/content/gdrive/My Drive/adversarial-xray/dataset/dataGAN/trainB_/9.jpeg',\n",
       " '/content/gdrive/My Drive/adversarial-xray/dataset/dataGAN/trainB_/10.jpeg']"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check\n",
    "path = glob('{}/dataset/%s/%s/*'.format(base_path) % (\"dataGAN\", \"trainB_\"))\n",
    "path[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dzGnIWJt8_Q0"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "from keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "class CycleGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 256 \n",
    "        self.img_cols = 256 \n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = 'dataGAN' #contains trainA, trainB, trainA_, trainB_\n",
    "        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n",
    "                                      img_res=(self.img_rows, self.img_cols))\n",
    "\n",
    "\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 32\n",
    "        self.df = 64\n",
    "\n",
    "        # Loss weights\n",
    "        self.lambda_cycle = 10.0                    # Cycle-consistency loss\n",
    "        self.lambda_id = 0.1 * self.lambda_cycle    # Identity loss\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminators\n",
    "        self.d_A = self.build_discriminator()\n",
    "        self.d_B = self.build_discriminator()\n",
    "        self.d_A.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "        self.d_B.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generators\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generators\n",
    "        self.g_AB = self.build_generator()\n",
    "        self.g_BA = self.build_generator()\n",
    "\n",
    "        # Input images from both domains\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        # Translate images to the other domain\n",
    "        fake_B = self.g_AB(img_A)\n",
    "        fake_A = self.g_BA(img_B)\n",
    "        # Translate images back to original domain\n",
    "        reconstr_A = self.g_BA(fake_B)\n",
    "        reconstr_B = self.g_AB(fake_A)\n",
    "        # Identity mapping of images\n",
    "        img_A_id = self.g_BA(img_A)\n",
    "        img_B_id = self.g_AB(img_B)\n",
    "\n",
    "        # For the combined model we will only train the generators\n",
    "        self.d_A.trainable = False\n",
    "        self.d_B.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images\n",
    "        valid_A = self.d_A(fake_A)\n",
    "        valid_B = self.d_B(fake_B)\n",
    "\n",
    "        # Combined model trains generators to fool discriminators\n",
    "        self.combined = Model(inputs=[img_A, img_B],\n",
    "                              outputs=[ valid_A, valid_B,\n",
    "                                        reconstr_A, reconstr_B,\n",
    "                                        img_A_id, img_B_id ])\n",
    "        self.combined.compile(loss=['mse', 'mse',\n",
    "                                    'mae', 'mae',\n",
    "                                    'mae', 'mae'],\n",
    "                            loss_weights=[  1, 1,\n",
    "                                            self.lambda_cycle, self.lambda_cycle,\n",
    "                                            self.lambda_id, self.lambda_id ],\n",
    "                            optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "        def conv2d(layer_input, filters, f_size=4):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            d = InstanceNormalization()(d)\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            u = InstanceNormalization()(u)\n",
    "            u = Concatenate()([u, skip_input])\n",
    "            return u\n",
    "\n",
    "        # Image input\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = conv2d(d0, self.gf)\n",
    "        d2 = conv2d(d1, self.gf*2)\n",
    "        d3 = conv2d(d2, self.gf*4)\n",
    "        d4 = conv2d(d3, self.gf*8)\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = deconv2d(d4, d3, self.gf*4)\n",
    "        u2 = deconv2d(u1, d2, self.gf*2)\n",
    "        u3 = deconv2d(u2, d1, self.gf)\n",
    "\n",
    "        u4 = UpSampling2D(size=2)(u3)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n",
    "\n",
    "        return Model(d0, output_img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        def d_layer(layer_input, filters, f_size=4, normalization=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if normalization:\n",
    "                d = InstanceNormalization()(d)\n",
    "            return d\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "\n",
    "        d1 = d_layer(img, self.df, normalization=False)\n",
    "        d2 = d_layer(d1, self.df*2)\n",
    "        d3 = d_layer(d2, self.df*4)\n",
    "        d4 = d_layer(d3, self.df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=1, sample_interval=50):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "        \n",
    "        # Make a log file\n",
    "        record_df = pd.DataFrame(columns=['epoch', 'd_Loss', 'accuracy', 'g_loss', 'adv', 'recon', 'id', 'elapsed_time'])\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print('epoch: ', epoch)\n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n",
    "\n",
    "                # ----------------------\n",
    "                #  Train Discriminators\n",
    "                # ----------------------\n",
    "\n",
    "                # Translate images to opposite domain\n",
    "                fake_B = self.g_AB.predict(imgs_A)\n",
    "                fake_A = self.g_BA.predict(imgs_B)\n",
    "\n",
    "                # Train the discriminators (original images = real / translated = Fake)\n",
    "                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
    "                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
    "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
    "\n",
    "                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n",
    "                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
    "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
    "\n",
    "                # Total disciminator loss\n",
    "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
    "\n",
    "\n",
    "                # ------------------\n",
    "                #  Train Generators\n",
    "                # ------------------\n",
    "\n",
    "                # Train the generators\n",
    "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n",
    "                                                        [valid, valid,\n",
    "                                                        imgs_A, imgs_B,\n",
    "                                                        imgs_A, imgs_B])\n",
    "\n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    self.sample_images(epoch, batch_i)\n",
    "            \n",
    "            \n",
    "            # Print updates\n",
    "            print(epoch,\"--------\", d_loss[0], g_loss[0], 100*d_loss[1])\n",
    "\n",
    "            # Log metrics at end of epoch            \n",
    "            new_row = {'epoch': epoch, 'd_Loss': d_loss[0], 'accuracy': 100*d_loss[1], 'g_loss': g_loss[0], 'adv': np.mean(g_loss[1:3]), 'recon': np.mean(g_loss[3:5]), 'id': np.mean(g_loss[5:6]), 'elapsed_time': elapsed_time}\n",
    "                                      \n",
    "            record_df = record_df.append(new_row, ignore_index=True)\n",
    "            record_df.to_csv(\"{}/record.csv\".format(model_path), index=0)\n",
    "            \n",
    "            # Save file at end of epoch.\n",
    "            print(\"Saving model at {} epoch.\".format(epoch))\n",
    "            self.g_AB.save(filepath='{}/{}'.format(model_path, \"b2m.h5\"))\n",
    "            keras.callbacks.ModelCheckpoint(filepath='{}/{}'.format(model_path, \"b2m.h5\"), verbose=1,save_best_only=True)\n",
    "\n",
    "            self.g_BA.save(filepath='{}/{}'.format(model_path, \"m2b.h5\"))\n",
    "            keras.callbacks.ModelCheckpoint(filepath='{}/{}'.format(base_path, \"m2b.h5\"), verbose=1,save_best_only=True)\n",
    "\n",
    "            self.combined.save(filepath='{}/{}'.format(model_path, \"model.h5\"))\n",
    "            keras.callbacks.ModelCheckpoint(filepath='{}/{}'.format(model_path, \"model.h5\"), verbose=1,save_best_only=True)   \n",
    "            \n",
    "        \n",
    "        print(\"Training finished...\")\n",
    "        print(\"Models Saved!\")\n",
    "\n",
    "\n",
    "    def sample_images(self, epoch, batch_i):\n",
    "        os.makedirs('{}/images/%s'.format(model_path) % self.dataset_name, exist_ok=True)\n",
    "        r, c = 2, 3\n",
    "\n",
    "        imgs_A = self.data_loader.load_data(domain=\"A_\", batch_size=1, is_testing=False)\n",
    "        imgs_B = self.data_loader.load_data(domain=\"B_\", batch_size=1, is_testing=False)\n",
    "\n",
    "        # Translate images to the other domain\n",
    "        fake_B = self.g_AB.predict(imgs_A)\n",
    "        fake_A = self.g_BA.predict(imgs_B)\n",
    "        # Translate back to original domain\n",
    "        reconstr_A = self.g_BA.predict(fake_B)\n",
    "        reconstr_B = self.g_AB.predict(fake_A)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Original', 'Translated', 'Reconstructed']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].set_title(titles[j])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"{}/images/%s/%d_%d.png\".format(model_path) % (self.dataset_name, epoch, batch_i))\n",
    "        plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15391762,
     "status": "ok",
     "timestamp": 1588425879832,
     "user": {
      "displayName": "Maria Mahbub",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQyYlcc7Ts8pou2N_rxNtZawQminV0SA-tjYzK=s64",
      "userId": "18117529587993011390"
     },
     "user_tz": 240
    },
    "id": "8MWnwzyDvFJ5",
    "outputId": "147b184d-1d93-4824-af6b-7cc1d6e3e3aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Training..\n",
      "epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:110: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:71: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:110: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:71: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -------- 0.19123337 5.6988907 70.99609375\n",
      "Saving model at 0 epoch.\n",
      "epoch:  1\n",
      "1 -------- 0.1160167 6.223659 84.47265625\n",
      "Saving model at 1 epoch.\n",
      "epoch:  2\n",
      "2 -------- 0.46067694 5.1422935 40.234375\n",
      "Saving model at 2 epoch.\n",
      "epoch:  3\n",
      "3 -------- 0.21338423 4.193062 65.4296875\n",
      "Saving model at 3 epoch.\n",
      "epoch:  4\n",
      "4 -------- 0.18581586 5.3530517 72.36328125\n",
      "Saving model at 4 epoch.\n",
      "epoch:  5\n",
      "5 -------- 0.101901345 4.5962815 90.33203125\n",
      "Saving model at 5 epoch.\n",
      "epoch:  6\n",
      "6 -------- 0.11092611 5.2593737 86.23046875\n",
      "Saving model at 6 epoch.\n",
      "epoch:  7\n",
      "7 -------- 0.04558455 5.1707153 97.0703125\n",
      "Saving model at 7 epoch.\n",
      "epoch:  8\n",
      "8 -------- 0.06436776 5.7664423 95.5078125\n",
      "Saving model at 8 epoch.\n",
      "epoch:  9\n",
      "9 -------- 0.039282177 5.1254616 97.94921875\n",
      "Saving model at 9 epoch.\n",
      "epoch:  10\n",
      "10 -------- 0.06422086 5.034731 94.921875\n",
      "Saving model at 10 epoch.\n",
      "epoch:  11\n",
      "11 -------- 0.031542435 4.7126365 98.53515625\n",
      "Saving model at 11 epoch.\n",
      "epoch:  12\n",
      "12 -------- 0.22483748 4.444845 73.828125\n",
      "Saving model at 12 epoch.\n",
      "epoch:  13\n",
      "13 -------- 0.073064074 4.4907346 92.3828125\n",
      "Saving model at 13 epoch.\n",
      "epoch:  14\n",
      "14 -------- 0.11452665 4.725861 83.10546875\n",
      "Saving model at 14 epoch.\n",
      "epoch:  15\n",
      "15 -------- 0.0817536 4.995824 93.45703125\n",
      "Saving model at 15 epoch.\n",
      "epoch:  16\n",
      "16 -------- 0.057561062 5.0709023 99.12109375\n",
      "Saving model at 16 epoch.\n",
      "epoch:  17\n",
      "17 -------- 0.03235542 4.565195 98.73046875\n",
      "Saving model at 17 epoch.\n",
      "epoch:  18\n",
      "18 -------- 0.05064699 4.5310225 98.33984375\n",
      "Saving model at 18 epoch.\n",
      "epoch:  19\n",
      "19 -------- 0.0317244 4.977976 99.51171875\n",
      "Saving model at 19 epoch.\n",
      "epoch:  20\n",
      "20 -------- 0.22260381 4.1283836 64.453125\n",
      "Saving model at 20 epoch.\n",
      "epoch:  21\n",
      "21 -------- 0.10515004 5.356607 80.56640625\n",
      "Saving model at 21 epoch.\n",
      "epoch:  22\n",
      "22 -------- 0.017543886 4.9500475 100.0\n",
      "Saving model at 22 epoch.\n",
      "epoch:  23\n",
      "23 -------- 0.10751556 4.787756 82.12890625\n",
      "Saving model at 23 epoch.\n",
      "epoch:  24\n",
      "24 -------- 0.07259131 6.1680326 88.8671875\n",
      "Saving model at 24 epoch.\n",
      "epoch:  25\n",
      "25 -------- 0.033033706 4.9277654 98.4375\n",
      "Saving model at 25 epoch.\n",
      "epoch:  26\n",
      "26 -------- 0.04161416 6.3304634 100.0\n",
      "Saving model at 26 epoch.\n",
      "epoch:  27\n",
      "27 -------- 0.026910186 3.8039203 99.90234375\n",
      "Saving model at 27 epoch.\n",
      "epoch:  28\n",
      "28 -------- 0.24062394 4.6363626 67.3828125\n",
      "Saving model at 28 epoch.\n",
      "epoch:  29\n",
      "29 -------- 0.1851021 4.7519135 61.81640625\n",
      "Saving model at 29 epoch.\n",
      "epoch:  30\n",
      "30 -------- 0.021058518 4.4071455 100.0\n",
      "Saving model at 30 epoch.\n",
      "epoch:  31\n",
      "31 -------- 0.010115938 5.8178706 99.609375\n",
      "Saving model at 31 epoch.\n",
      "epoch:  32\n",
      "32 -------- 0.026651848 4.0277033 98.92578125\n",
      "Saving model at 32 epoch.\n",
      "epoch:  33\n",
      "33 -------- 0.09933177 4.8669777 86.1328125\n",
      "Saving model at 33 epoch.\n",
      "epoch:  34\n",
      "34 -------- 0.07856847 4.6580477 98.53515625\n",
      "Saving model at 34 epoch.\n",
      "epoch:  35\n",
      "35 -------- 0.09288686 4.6317396 88.96484375\n",
      "Saving model at 35 epoch.\n",
      "epoch:  36\n",
      "36 -------- 0.08330937 4.195234 85.25390625\n",
      "Saving model at 36 epoch.\n",
      "epoch:  37\n",
      "37 -------- 0.03924542 3.8133516 100.0\n",
      "Saving model at 37 epoch.\n",
      "epoch:  38\n",
      "38 -------- 0.039328642 4.1259546 98.828125\n",
      "Saving model at 38 epoch.\n",
      "epoch:  39\n",
      "39 -------- 0.034561176 4.331193 100.0\n",
      "Saving model at 39 epoch.\n",
      "epoch:  40\n",
      "40 -------- 0.018957604 4.4646263 100.0\n",
      "Saving model at 40 epoch.\n",
      "epoch:  41\n",
      "41 -------- 0.045253165 3.8149133 97.94921875\n",
      "Saving model at 41 epoch.\n",
      "epoch:  42\n",
      "42 -------- 0.06741081 4.944967 95.8984375\n",
      "Saving model at 42 epoch.\n",
      "epoch:  43\n",
      "43 -------- 0.04728339 4.467216 100.0\n",
      "Saving model at 43 epoch.\n",
      "epoch:  44\n",
      "44 -------- 0.019369256 4.395082 99.70703125\n",
      "Saving model at 44 epoch.\n",
      "epoch:  45\n",
      "45 -------- 0.033818953 4.0317683 98.73046875\n",
      "Saving model at 45 epoch.\n",
      "epoch:  46\n",
      "46 -------- 0.2599349 4.9103775 70.99609375\n",
      "Saving model at 46 epoch.\n",
      "epoch:  47\n",
      "47 -------- 0.041902337 3.727422 97.75390625\n",
      "Saving model at 47 epoch.\n",
      "epoch:  48\n",
      "48 -------- 0.100913584 3.61647 90.0390625\n",
      "Saving model at 48 epoch.\n",
      "epoch:  49\n",
      "49 -------- 0.044345677 3.9975238 95.3125\n",
      "Saving model at 49 epoch.\n",
      "epoch:  50\n",
      "50 -------- 0.3302749 3.4734478 66.9921875\n",
      "Saving model at 50 epoch.\n",
      "epoch:  51\n",
      "51 -------- 0.09028161 3.6749978 92.7734375\n",
      "Saving model at 51 epoch.\n",
      "epoch:  52\n",
      "52 -------- 0.03390991 4.5678067 99.90234375\n",
      "Saving model at 52 epoch.\n",
      "epoch:  53\n",
      "53 -------- 0.019243844 4.5254803 100.0\n",
      "Saving model at 53 epoch.\n",
      "epoch:  54\n",
      "54 -------- 0.041007847 3.7487144 99.4140625\n",
      "Saving model at 54 epoch.\n",
      "epoch:  55\n",
      "55 -------- 0.1004301 3.8150287 87.79296875\n",
      "Saving model at 55 epoch.\n",
      "epoch:  56\n",
      "56 -------- 0.029529803 3.7167172 98.828125\n",
      "Saving model at 56 epoch.\n",
      "epoch:  57\n",
      "57 -------- 0.040176533 3.8853533 99.21875\n",
      "Saving model at 57 epoch.\n",
      "epoch:  58\n",
      "58 -------- 0.055307366 3.9343393 98.4375\n",
      "Saving model at 58 epoch.\n",
      "epoch:  59\n",
      "59 -------- 0.027037254 3.4368987 99.8046875\n",
      "Saving model at 59 epoch.\n",
      "epoch:  60\n",
      "60 -------- 0.057702363 4.445149 99.4140625\n",
      "Saving model at 60 epoch.\n",
      "epoch:  61\n",
      "61 -------- 0.043498147 4.394935 99.31640625\n",
      "Saving model at 61 epoch.\n",
      "epoch:  62\n",
      "62 -------- 0.011529731 3.464202 99.90234375\n",
      "Saving model at 62 epoch.\n",
      "epoch:  63\n",
      "63 -------- 0.08465876 3.9887044 90.234375\n",
      "Saving model at 63 epoch.\n",
      "epoch:  64\n",
      "64 -------- 0.039618794 4.4936705 99.4140625\n",
      "Saving model at 64 epoch.\n",
      "epoch:  65\n",
      "65 -------- 0.02185245 4.130364 100.0\n",
      "Saving model at 65 epoch.\n",
      "epoch:  66\n",
      "66 -------- 0.024273857 4.331776 100.0\n",
      "Saving model at 66 epoch.\n",
      "epoch:  67\n",
      "67 -------- 0.0363412 3.7776322 99.609375\n",
      "Saving model at 67 epoch.\n",
      "epoch:  68\n",
      "68 -------- 0.19816242 4.669144 71.875\n",
      "Saving model at 68 epoch.\n",
      "epoch:  69\n",
      "69 -------- 0.028572705 4.4939394 100.0\n",
      "Saving model at 69 epoch.\n",
      "epoch:  70\n",
      "70 -------- 0.06116879 3.7236774 97.265625\n",
      "Saving model at 70 epoch.\n",
      "epoch:  71\n",
      "71 -------- 0.056721944 4.436492 96.97265625\n",
      "Saving model at 71 epoch.\n",
      "epoch:  72\n",
      "72 -------- 0.11203454 4.72785 95.3125\n",
      "Saving model at 72 epoch.\n",
      "epoch:  73\n",
      "73 -------- 0.048553266 4.6272206 99.21875\n",
      "Saving model at 73 epoch.\n",
      "epoch:  74\n",
      "74 -------- 0.014517862 4.878552 100.0\n",
      "Saving model at 74 epoch.\n",
      "epoch:  75\n",
      "75 -------- 0.029323595 4.375917 99.90234375\n",
      "Saving model at 75 epoch.\n",
      "epoch:  76\n",
      "76 -------- 0.02107124 4.2314324 98.6328125\n",
      "Saving model at 76 epoch.\n",
      "epoch:  77\n",
      "77 -------- 0.05923881 4.16897 98.2421875\n",
      "Saving model at 77 epoch.\n",
      "epoch:  78\n",
      "78 -------- 0.048300337 4.459043 99.0234375\n",
      "Saving model at 78 epoch.\n",
      "epoch:  79\n",
      "79 -------- 0.040447526 3.4580274 99.8046875\n",
      "Saving model at 79 epoch.\n",
      "epoch:  80\n",
      "80 -------- 0.046585213 4.593007 99.51171875\n",
      "Saving model at 80 epoch.\n",
      "epoch:  81\n",
      "81 -------- 0.019404419 3.7911532 100.0\n",
      "Saving model at 81 epoch.\n",
      "epoch:  82\n",
      "82 -------- 0.0962626 3.9475832 91.30859375\n",
      "Saving model at 82 epoch.\n",
      "epoch:  83\n",
      "83 -------- 0.036033593 5.355961 100.0\n",
      "Saving model at 83 epoch.\n",
      "epoch:  84\n",
      "84 -------- 0.09607836 6.683166 95.703125\n",
      "Saving model at 84 epoch.\n",
      "epoch:  85\n",
      "85 -------- 0.007036354 3.847216 100.0\n",
      "Saving model at 85 epoch.\n",
      "epoch:  86\n",
      "86 -------- 0.05932478 3.9370203 95.8984375\n",
      "Saving model at 86 epoch.\n",
      "epoch:  87\n",
      "87 -------- 0.060202576 5.6238155 99.21875\n",
      "Saving model at 87 epoch.\n",
      "epoch:  88\n",
      "88 -------- 0.059961308 4.1578083 98.046875\n",
      "Saving model at 88 epoch.\n",
      "epoch:  89\n",
      "89 -------- 0.044138893 3.538001 99.21875\n",
      "Saving model at 89 epoch.\n",
      "epoch:  90\n",
      "90 -------- 0.032642275 4.149219 100.0\n",
      "Saving model at 90 epoch.\n",
      "epoch:  91\n",
      "91 -------- 0.03235566 3.5450428 100.0\n",
      "Saving model at 91 epoch.\n",
      "epoch:  92\n",
      "92 -------- 0.025551178 4.4774013 99.90234375\n",
      "Saving model at 92 epoch.\n",
      "epoch:  93\n",
      "93 -------- 0.03559883 3.9777272 98.828125\n",
      "Saving model at 93 epoch.\n",
      "epoch:  94\n",
      "94 -------- 0.011509804 4.799597 99.51171875\n",
      "Saving model at 94 epoch.\n",
      "epoch:  95\n",
      "95 -------- 0.020424165 4.247409 100.0\n",
      "Saving model at 95 epoch.\n",
      "epoch:  96\n",
      "96 -------- 0.045229103 4.412182 98.828125\n",
      "Saving model at 96 epoch.\n",
      "epoch:  97\n",
      "97 -------- 0.110501245 3.6719043 77.63671875\n",
      "Saving model at 97 epoch.\n",
      "epoch:  98\n",
      "98 -------- 0.031165 3.5891612 99.609375\n",
      "Saving model at 98 epoch.\n",
      "epoch:  99\n",
      "99 -------- 0.017472507 4.858256 100.0\n",
      "Saving model at 99 epoch.\n",
      "epoch:  100\n",
      "100 -------- 0.061039623 3.749204 96.09375\n",
      "Saving model at 100 epoch.\n",
      "epoch:  101\n",
      "101 -------- 0.046494488 4.001274 98.92578125\n",
      "Saving model at 101 epoch.\n",
      "epoch:  102\n",
      "102 -------- 0.015034797 4.282316 100.0\n",
      "Saving model at 102 epoch.\n",
      "epoch:  103\n",
      "103 -------- 0.023062779 4.705196 99.8046875\n",
      "Saving model at 103 epoch.\n",
      "epoch:  104\n",
      "104 -------- 0.033961765 3.808745 100.0\n",
      "Saving model at 104 epoch.\n",
      "epoch:  105\n",
      "105 -------- 0.070045374 3.8096101 99.4140625\n",
      "Saving model at 105 epoch.\n",
      "epoch:  106\n",
      "106 -------- 0.066397935 3.806428 97.4609375\n",
      "Saving model at 106 epoch.\n",
      "epoch:  107\n",
      "107 -------- 0.10781062 3.9122436 79.1015625\n",
      "Saving model at 107 epoch.\n",
      "epoch:  108\n",
      "108 -------- 0.14189959 4.4327493 75.390625\n",
      "Saving model at 108 epoch.\n",
      "epoch:  109\n",
      "109 -------- 0.039905082 6.231443 99.8046875\n",
      "Saving model at 109 epoch.\n",
      "epoch:  110\n",
      "110 -------- 0.05630807 3.901333 95.80078125\n",
      "Saving model at 110 epoch.\n",
      "epoch:  111\n",
      "111 -------- 0.011330469 3.8528483 99.90234375\n",
      "Saving model at 111 epoch.\n",
      "epoch:  112\n",
      "112 -------- 0.047811024 3.9195535 96.2890625\n",
      "Saving model at 112 epoch.\n",
      "epoch:  113\n",
      "113 -------- 0.04663074 5.010134 99.4140625\n",
      "Saving model at 113 epoch.\n",
      "epoch:  114\n",
      "114 -------- 0.113716386 3.783101 85.44921875\n",
      "Saving model at 114 epoch.\n",
      "epoch:  115\n",
      "115 -------- 0.04735505 4.2733502 99.90234375\n",
      "Saving model at 115 epoch.\n",
      "epoch:  116\n",
      "116 -------- 0.047886133 3.9368174 99.609375\n",
      "Saving model at 116 epoch.\n",
      "epoch:  117\n",
      "117 -------- 0.05654361 3.435965 97.55859375\n",
      "Saving model at 117 epoch.\n",
      "epoch:  118\n",
      "118 -------- 0.024431592 3.9868164 100.0\n",
      "Saving model at 118 epoch.\n",
      "epoch:  119\n",
      "119 -------- 0.04892894 3.8900795 99.12109375\n",
      "Saving model at 119 epoch.\n",
      "epoch:  120\n",
      "120 -------- 0.21597926 3.739254 71.6796875\n",
      "Saving model at 120 epoch.\n",
      "epoch:  121\n",
      "121 -------- 0.18309735 3.8154533 74.609375\n",
      "Saving model at 121 epoch.\n",
      "epoch:  122\n",
      "122 -------- 0.122745976 3.2110796 82.2265625\n",
      "Saving model at 122 epoch.\n",
      "epoch:  123\n",
      "123 -------- 0.275368 3.4611268 73.53515625\n",
      "Saving model at 123 epoch.\n",
      "epoch:  124\n",
      "124 -------- 0.08839624 4.29606 96.38671875\n",
      "Saving model at 124 epoch.\n",
      "epoch:  125\n",
      "125 -------- 0.030818922 3.7584143 99.51171875\n",
      "Saving model at 125 epoch.\n",
      "epoch:  126\n",
      "126 -------- 0.026089473 4.4470377 99.609375\n",
      "Saving model at 126 epoch.\n",
      "epoch:  127\n",
      "127 -------- 0.041786656 3.6642184 99.8046875\n",
      "Saving model at 127 epoch.\n",
      "epoch:  128\n",
      "128 -------- 0.006770435 3.822742 100.0\n",
      "Saving model at 128 epoch.\n",
      "epoch:  129\n",
      "129 -------- 0.025183382 3.3714807 100.0\n",
      "Saving model at 129 epoch.\n",
      "epoch:  130\n",
      "130 -------- 0.039889667 3.9481385 99.609375\n",
      "Saving model at 130 epoch.\n",
      "epoch:  131\n",
      "131 -------- 0.080604665 4.0971646 84.86328125\n",
      "Saving model at 131 epoch.\n",
      "epoch:  132\n",
      "132 -------- 0.035857245 4.117429 99.609375\n",
      "Saving model at 132 epoch.\n",
      "epoch:  133\n",
      "133 -------- 0.06864098 3.4199386 94.43359375\n",
      "Saving model at 133 epoch.\n",
      "epoch:  134\n",
      "134 -------- 0.03456656 4.4391375 98.4375\n",
      "Saving model at 134 epoch.\n",
      "epoch:  135\n",
      "135 -------- 0.035912894 5.2840867 99.0234375\n",
      "Saving model at 135 epoch.\n",
      "epoch:  136\n",
      "136 -------- 0.010390217 4.209039 100.0\n",
      "Saving model at 136 epoch.\n",
      "epoch:  137\n",
      "137 -------- 0.023840472 3.8475587 99.70703125\n",
      "Saving model at 137 epoch.\n",
      "epoch:  138\n",
      "138 -------- 0.1063138 4.066476 84.27734375\n",
      "Saving model at 138 epoch.\n",
      "epoch:  139\n",
      "139 -------- 0.07423758 4.315871 92.3828125\n",
      "Saving model at 139 epoch.\n",
      "epoch:  140\n",
      "140 -------- 0.08894251 3.7137206 97.16796875\n",
      "Saving model at 140 epoch.\n",
      "epoch:  141\n",
      "141 -------- 0.032524563 3.6339715 99.90234375\n",
      "Saving model at 141 epoch.\n",
      "epoch:  142\n",
      "142 -------- 0.015316079 3.8954144 99.8046875\n",
      "Saving model at 142 epoch.\n",
      "epoch:  143\n",
      "143 -------- 0.043003455 4.4038343 98.92578125\n",
      "Saving model at 143 epoch.\n",
      "epoch:  144\n",
      "144 -------- 0.057424657 3.9153497 99.31640625\n",
      "Saving model at 144 epoch.\n",
      "epoch:  145\n",
      "145 -------- 0.16418132 4.370297 73.2421875\n",
      "Saving model at 145 epoch.\n",
      "epoch:  146\n",
      "146 -------- 0.04500724 4.5823474 98.33984375\n",
      "Saving model at 146 epoch.\n",
      "epoch:  147\n",
      "147 -------- 0.05360093 4.251107 98.92578125\n",
      "Saving model at 147 epoch.\n",
      "epoch:  148\n",
      "148 -------- 0.042602405 4.0233545 99.12109375\n",
      "Saving model at 148 epoch.\n",
      "epoch:  149\n",
      "149 -------- 0.03293737 3.6873689 99.8046875\n",
      "Saving model at 149 epoch.\n",
      "epoch:  150\n",
      "150 -------- 0.04341536 3.7253354 99.12109375\n",
      "Saving model at 150 epoch.\n",
      "epoch:  151\n",
      "151 -------- 0.040098313 3.9225302 99.70703125\n",
      "Saving model at 151 epoch.\n",
      "epoch:  152\n",
      "152 -------- 0.15060052 3.8744447 74.609375\n",
      "Saving model at 152 epoch.\n",
      "epoch:  153\n",
      "153 -------- 0.06659897 4.229896 94.53125\n",
      "Saving model at 153 epoch.\n",
      "epoch:  154\n",
      "154 -------- 0.032840103 3.7436378 99.8046875\n",
      "Saving model at 154 epoch.\n",
      "epoch:  155\n",
      "155 -------- 0.17686856 3.7782123 64.453125\n",
      "Saving model at 155 epoch.\n",
      "epoch:  156\n",
      "156 -------- 0.025316048 4.3100815 99.8046875\n",
      "Saving model at 156 epoch.\n",
      "epoch:  157\n",
      "157 -------- 0.012049396 4.3252497 99.90234375\n",
      "Saving model at 157 epoch.\n",
      "epoch:  158\n",
      "158 -------- 0.11059947 4.092458 85.83984375\n",
      "Saving model at 158 epoch.\n",
      "epoch:  159\n",
      "159 -------- 0.13727659 4.283246 80.76171875\n",
      "Saving model at 159 epoch.\n",
      "epoch:  160\n",
      "160 -------- 0.024745245 3.9756923 99.70703125\n",
      "Saving model at 160 epoch.\n",
      "epoch:  161\n",
      "161 -------- 0.030107912 3.4543142 99.90234375\n",
      "Saving model at 161 epoch.\n",
      "epoch:  162\n",
      "162 -------- 0.118969925 3.6422405 82.03125\n",
      "Saving model at 162 epoch.\n",
      "epoch:  163\n",
      "163 -------- 0.047324635 3.6808567 99.31640625\n",
      "Saving model at 163 epoch.\n",
      "epoch:  164\n",
      "164 -------- 0.08421656 3.650577 89.94140625\n",
      "Saving model at 164 epoch.\n",
      "epoch:  165\n",
      "165 -------- 0.026801825 3.9934607 100.0\n",
      "Saving model at 165 epoch.\n",
      "epoch:  166\n",
      "166 -------- 0.05668486 3.7442358 99.21875\n",
      "Saving model at 166 epoch.\n",
      "epoch:  167\n",
      "167 -------- 0.09499173 3.9350634 87.01171875\n",
      "Saving model at 167 epoch.\n",
      "epoch:  168\n",
      "168 -------- 0.11325306 3.2480638 92.1875\n",
      "Saving model at 168 epoch.\n",
      "epoch:  169\n",
      "169 -------- 0.034761276 4.016247 99.31640625\n",
      "Saving model at 169 epoch.\n",
      "epoch:  170\n",
      "170 -------- 0.012501519 4.0158777 99.70703125\n",
      "Saving model at 170 epoch.\n",
      "epoch:  171\n",
      "171 -------- 0.08269046 3.677659 92.87109375\n",
      "Saving model at 171 epoch.\n",
      "epoch:  172\n",
      "172 -------- 0.038370352 3.7427363 98.4375\n",
      "Saving model at 172 epoch.\n",
      "epoch:  173\n",
      "173 -------- 0.023783254 4.1947947 99.8046875\n",
      "Saving model at 173 epoch.\n",
      "epoch:  174\n",
      "174 -------- 0.16674164 5.292832 77.05078125\n",
      "Saving model at 174 epoch.\n",
      "epoch:  175\n",
      "175 -------- 0.019740805 4.098923 99.609375\n",
      "Saving model at 175 epoch.\n",
      "epoch:  176\n",
      "176 -------- 0.052192476 3.3140197 95.01953125\n",
      "Saving model at 176 epoch.\n",
      "epoch:  177\n",
      "177 -------- 0.17994015 4.207246 72.4609375\n",
      "Saving model at 177 epoch.\n",
      "epoch:  178\n",
      "178 -------- 0.06279299 4.0309186 97.75390625\n",
      "Saving model at 178 epoch.\n",
      "epoch:  179\n",
      "179 -------- 0.08112429 3.8446548 96.875\n",
      "Saving model at 179 epoch.\n",
      "epoch:  180\n",
      "180 -------- 0.066598326 4.029593 96.58203125\n",
      "Saving model at 180 epoch.\n",
      "epoch:  181\n",
      "181 -------- 0.012304135 3.7147686 99.70703125\n",
      "Saving model at 181 epoch.\n",
      "epoch:  182\n",
      "182 -------- 0.045817986 4.0037394 98.828125\n",
      "Saving model at 182 epoch.\n",
      "epoch:  183\n",
      "183 -------- 0.08947581 3.7163897 91.40625\n",
      "Saving model at 183 epoch.\n",
      "epoch:  184\n",
      "184 -------- 0.0643249 3.3571365 96.38671875\n",
      "Saving model at 184 epoch.\n",
      "epoch:  185\n",
      "185 -------- 0.109007224 4.1920652 94.140625\n",
      "Saving model at 185 epoch.\n",
      "epoch:  186\n",
      "186 -------- 0.043961 3.8181176 99.51171875\n",
      "Saving model at 186 epoch.\n",
      "epoch:  187\n",
      "187 -------- 0.027406828 3.8468645 99.90234375\n",
      "Saving model at 187 epoch.\n",
      "epoch:  188\n",
      "188 -------- 0.06698798 3.9020894 97.36328125\n",
      "Saving model at 188 epoch.\n",
      "epoch:  189\n",
      "189 -------- 0.07071462 3.918026 97.0703125\n",
      "Saving model at 189 epoch.\n",
      "epoch:  190\n",
      "190 -------- 0.08273973 3.56944 96.484375\n",
      "Saving model at 190 epoch.\n",
      "epoch:  191\n",
      "191 -------- 0.031632118 4.1901693 98.14453125\n",
      "Saving model at 191 epoch.\n",
      "epoch:  192\n",
      "192 -------- 0.046564423 4.7399926 99.12109375\n",
      "Saving model at 192 epoch.\n",
      "epoch:  193\n",
      "193 -------- 0.10047285 3.0685875 92.48046875\n",
      "Saving model at 193 epoch.\n",
      "epoch:  194\n",
      "194 -------- 0.09144388 3.189451 82.421875\n",
      "Saving model at 194 epoch.\n",
      "epoch:  195\n",
      "195 -------- 0.033608988 3.7152593 100.0\n",
      "Saving model at 195 epoch.\n",
      "epoch:  196\n",
      "196 -------- 0.07809859 3.2263746 98.6328125\n",
      "Saving model at 196 epoch.\n",
      "epoch:  197\n",
      "197 -------- 0.026658094 4.254991 99.609375\n",
      "Saving model at 197 epoch.\n",
      "epoch:  198\n",
      "198 -------- 0.031744547 3.938141 100.0\n",
      "Saving model at 198 epoch.\n",
      "epoch:  199\n",
      "199 -------- 0.19541383 3.569931 75.48828125\n",
      "Saving model at 199 epoch.\n",
      "epoch:  200\n",
      "200 -------- 0.10313945 3.6834688 90.91796875\n",
      "Saving model at 200 epoch.\n",
      "epoch:  201\n",
      "201 -------- 0.05363471 3.6305845 98.828125\n",
      "Saving model at 201 epoch.\n",
      "epoch:  202\n",
      "202 -------- 0.19363338 3.5394979 74.51171875\n",
      "Saving model at 202 epoch.\n",
      "epoch:  203\n",
      "203 -------- 0.08633374 4.471543 89.16015625\n",
      "Saving model at 203 epoch.\n",
      "epoch:  204\n",
      "204 -------- 0.043107003 3.1848612 98.2421875\n",
      "Saving model at 204 epoch.\n",
      "epoch:  205\n",
      "205 -------- 0.036974415 4.343697 98.73046875\n",
      "Saving model at 205 epoch.\n",
      "epoch:  206\n",
      "206 -------- 0.023976594 3.885118 98.73046875\n",
      "Saving model at 206 epoch.\n",
      "epoch:  207\n",
      "207 -------- 0.031794086 3.7937753 98.2421875\n",
      "Saving model at 207 epoch.\n",
      "epoch:  208\n",
      "208 -------- 0.030243555 4.1322308 99.31640625\n",
      "Saving model at 208 epoch.\n",
      "epoch:  209\n",
      "209 -------- 0.053657442 3.9728038 99.21875\n",
      "Saving model at 209 epoch.\n",
      "epoch:  210\n",
      "210 -------- 0.077537596 3.623483 91.796875\n",
      "Saving model at 210 epoch.\n",
      "epoch:  211\n",
      "211 -------- 0.055160966 3.5344794 97.55859375\n",
      "Saving model at 211 epoch.\n",
      "epoch:  212\n",
      "212 -------- 0.030180603 3.5040689 99.8046875\n",
      "Saving model at 212 epoch.\n",
      "epoch:  213\n",
      "213 -------- 0.08619292 2.9433203 84.47265625\n",
      "Saving model at 213 epoch.\n",
      "epoch:  214\n",
      "214 -------- 0.047284164 3.1871665 97.265625\n",
      "Saving model at 214 epoch.\n",
      "epoch:  215\n",
      "215 -------- 0.09301588 3.2829285 85.15625\n",
      "Saving model at 215 epoch.\n",
      "epoch:  216\n",
      "216 -------- 0.10306555 3.7624753 90.625\n",
      "Saving model at 216 epoch.\n",
      "epoch:  217\n",
      "217 -------- 0.08081457 4.1078815 94.7265625\n",
      "Saving model at 217 epoch.\n",
      "epoch:  218\n",
      "218 -------- 0.24009311 3.675785 74.90234375\n",
      "Saving model at 218 epoch.\n",
      "epoch:  219\n",
      "219 -------- 0.11478013 3.2225626 91.015625\n",
      "Saving model at 219 epoch.\n",
      "epoch:  220\n",
      "220 -------- 0.027314078 3.5982666 99.8046875\n",
      "Saving model at 220 epoch.\n",
      "epoch:  221\n",
      "221 -------- 0.108540036 3.5236752 86.62109375\n",
      "Saving model at 221 epoch.\n",
      "epoch:  222\n",
      "222 -------- 0.033192784 3.4253383 99.90234375\n",
      "Saving model at 222 epoch.\n",
      "epoch:  223\n",
      "223 -------- 0.060469326 3.7639718 97.55859375\n",
      "Saving model at 223 epoch.\n",
      "epoch:  224\n",
      "224 -------- 0.024477107 3.8705988 100.0\n",
      "Saving model at 224 epoch.\n",
      "epoch:  225\n",
      "225 -------- 0.218219 2.9185526 75.0\n",
      "Saving model at 225 epoch.\n",
      "epoch:  226\n",
      "226 -------- 0.027068364 3.5722122 99.70703125\n",
      "Saving model at 226 epoch.\n",
      "epoch:  227\n",
      "227 -------- 0.09950371 3.7384317 90.72265625\n",
      "Saving model at 227 epoch.\n",
      "epoch:  228\n",
      "228 -------- 0.07423842 3.7301466 97.8515625\n",
      "Saving model at 228 epoch.\n",
      "epoch:  229\n",
      "229 -------- 0.04034527 3.6398685 99.0234375\n",
      "Saving model at 229 epoch.\n",
      "epoch:  230\n",
      "230 -------- 0.025526334 3.216968 99.4140625\n",
      "Saving model at 230 epoch.\n",
      "epoch:  231\n",
      "231 -------- 0.073434114 2.8358252 87.5\n",
      "Saving model at 231 epoch.\n",
      "epoch:  232\n",
      "232 -------- 0.008813269 3.551187 100.0\n",
      "Saving model at 232 epoch.\n",
      "epoch:  233\n",
      "233 -------- 0.043668445 3.7372687 98.92578125\n",
      "Saving model at 233 epoch.\n",
      "epoch:  234\n",
      "234 -------- 0.02325505 3.775303 99.90234375\n",
      "Saving model at 234 epoch.\n",
      "epoch:  235\n",
      "235 -------- 0.04875888 3.703205 99.70703125\n",
      "Saving model at 235 epoch.\n",
      "epoch:  236\n",
      "236 -------- 0.058432873 3.452767 96.58203125\n",
      "Saving model at 236 epoch.\n",
      "epoch:  237\n",
      "237 -------- 0.032822743 3.4254136 99.70703125\n",
      "Saving model at 237 epoch.\n",
      "epoch:  238\n",
      "238 -------- 0.05505529 3.6149375 98.4375\n",
      "Saving model at 238 epoch.\n",
      "epoch:  239\n",
      "239 -------- 0.035901614 3.6086614 100.0\n",
      "Saving model at 239 epoch.\n",
      "epoch:  240\n",
      "240 -------- 0.3271696 3.482081 71.2890625\n",
      "Saving model at 240 epoch.\n",
      "epoch:  241\n",
      "241 -------- 0.110583544 3.2553463 92.96875\n",
      "Saving model at 241 epoch.\n",
      "epoch:  242\n",
      "242 -------- 0.029925091 3.962384 98.14453125\n",
      "Saving model at 242 epoch.\n",
      "epoch:  243\n",
      "243 -------- 0.022730406 3.7263849 99.8046875\n",
      "Saving model at 243 epoch.\n",
      "epoch:  244\n",
      "244 -------- 0.10641676 3.7324843 90.234375\n",
      "Saving model at 244 epoch.\n",
      "epoch:  245\n",
      "245 -------- 0.051893592 3.6505897 97.94921875\n",
      "Saving model at 245 epoch.\n",
      "epoch:  246\n",
      "246 -------- 0.01976433 3.4842038 100.0\n",
      "Saving model at 246 epoch.\n",
      "epoch:  247\n",
      "247 -------- 0.09652779 3.8204832 95.1171875\n",
      "Saving model at 247 epoch.\n",
      "epoch:  248\n",
      "248 -------- 0.04070085 3.5623226 98.92578125\n",
      "Saving model at 248 epoch.\n",
      "epoch:  249\n",
      "249 -------- 0.029400751 3.558136 100.0\n",
      "Saving model at 249 epoch.\n",
      "epoch:  250\n",
      "250 -------- 0.049416605 3.928943 99.21875\n",
      "Saving model at 250 epoch.\n",
      "epoch:  251\n",
      "251 -------- 0.05819248 3.564801 99.70703125\n",
      "Saving model at 251 epoch.\n",
      "epoch:  252\n",
      "252 -------- 0.049683318 3.8217404 99.4140625\n",
      "Saving model at 252 epoch.\n",
      "epoch:  253\n",
      "253 -------- 0.2894535 3.7425232 35.15625\n",
      "Saving model at 253 epoch.\n",
      "epoch:  254\n",
      "254 -------- 0.13404526 2.6597173 76.26953125\n",
      "Saving model at 254 epoch.\n",
      "epoch:  255\n",
      "255 -------- 0.029231489 3.3108985 99.0234375\n",
      "Saving model at 255 epoch.\n",
      "epoch:  256\n",
      "256 -------- 0.016985862 3.6687272 99.51171875\n",
      "Saving model at 256 epoch.\n",
      "epoch:  257\n",
      "257 -------- 0.036822177 3.4784992 99.21875\n",
      "Saving model at 257 epoch.\n",
      "epoch:  258\n",
      "258 -------- 0.046845097 3.5288286 98.73046875\n",
      "Saving model at 258 epoch.\n",
      "epoch:  259\n",
      "259 -------- 0.14040014 3.1526651 75.0\n",
      "Saving model at 259 epoch.\n",
      "epoch:  260\n",
      "260 -------- 0.07053661 3.4731786 96.875\n",
      "Saving model at 260 epoch.\n",
      "epoch:  261\n",
      "261 -------- 0.12340303 3.1677496 93.9453125\n",
      "Saving model at 261 epoch.\n",
      "epoch:  262\n",
      "262 -------- 0.025693953 3.4517672 99.51171875\n",
      "Saving model at 262 epoch.\n",
      "epoch:  263\n",
      "263 -------- 0.13022521 3.9096012 83.88671875\n",
      "Saving model at 263 epoch.\n",
      "epoch:  264\n",
      "264 -------- 0.024172109 3.6385286 99.51171875\n",
      "Saving model at 264 epoch.\n",
      "epoch:  265\n",
      "265 -------- 0.04281735 3.580133 98.046875\n",
      "Saving model at 265 epoch.\n",
      "epoch:  266\n",
      "266 -------- 0.052002966 3.396288 99.70703125\n",
      "Saving model at 266 epoch.\n",
      "epoch:  267\n",
      "267 -------- 0.17067 3.0901885 68.26171875\n",
      "Saving model at 267 epoch.\n",
      "epoch:  268\n",
      "268 -------- 0.039924294 3.5885212 99.609375\n",
      "Saving model at 268 epoch.\n",
      "epoch:  269\n",
      "269 -------- 0.025861066 3.466102 100.0\n",
      "Saving model at 269 epoch.\n",
      "epoch:  270\n",
      "270 -------- 0.028403725 3.1851265 99.31640625\n",
      "Saving model at 270 epoch.\n",
      "epoch:  271\n",
      "271 -------- 0.06635259 3.472253 98.92578125\n",
      "Saving model at 271 epoch.\n",
      "epoch:  272\n",
      "272 -------- 0.10063341 3.6426067 91.89453125\n",
      "Saving model at 272 epoch.\n",
      "epoch:  273\n",
      "273 -------- 0.070250355 3.5346754 93.75\n",
      "Saving model at 273 epoch.\n",
      "epoch:  274\n",
      "274 -------- 0.16293885 3.6375344 75.87890625\n",
      "Saving model at 274 epoch.\n",
      "epoch:  275\n",
      "275 -------- 0.04409591 3.811662 99.8046875\n",
      "Saving model at 275 epoch.\n",
      "epoch:  276\n",
      "276 -------- 0.044310994 3.7984638 99.21875\n",
      "Saving model at 276 epoch.\n",
      "epoch:  277\n",
      "277 -------- 0.11905725 3.581726 87.890625\n",
      "Saving model at 277 epoch.\n",
      "epoch:  278\n",
      "278 -------- 0.03898754 3.299472 98.2421875\n",
      "Saving model at 278 epoch.\n",
      "epoch:  279\n",
      "279 -------- 0.14827909 3.5088966 75.68359375\n",
      "Saving model at 279 epoch.\n",
      "epoch:  280\n",
      "280 -------- 0.025250804 3.25636 99.90234375\n",
      "Saving model at 280 epoch.\n",
      "epoch:  281\n",
      "281 -------- 0.0072771683 2.9092116 100.0\n",
      "Saving model at 281 epoch.\n",
      "epoch:  282\n",
      "282 -------- 0.018673984 3.4072356 100.0\n",
      "Saving model at 282 epoch.\n",
      "epoch:  283\n",
      "283 -------- 0.018784031 3.6578276 100.0\n",
      "Saving model at 283 epoch.\n",
      "epoch:  284\n",
      "284 -------- 0.024656408 3.5607831 100.0\n",
      "Saving model at 284 epoch.\n",
      "epoch:  285\n",
      "285 -------- 0.014869534 2.9210868 99.8046875\n",
      "Saving model at 285 epoch.\n",
      "epoch:  286\n",
      "286 -------- 0.05229142 2.9276638 100.0\n",
      "Saving model at 286 epoch.\n",
      "epoch:  287\n",
      "287 -------- 0.01364167 3.0153198 100.0\n",
      "Saving model at 287 epoch.\n",
      "epoch:  288\n",
      "288 -------- 0.013812399 3.5912585 99.90234375\n",
      "Saving model at 288 epoch.\n",
      "epoch:  289\n",
      "289 -------- 0.031899843 3.3780494 99.90234375\n",
      "Saving model at 289 epoch.\n",
      "epoch:  290\n",
      "290 -------- 0.052080844 2.8317454 98.73046875\n",
      "Saving model at 290 epoch.\n",
      "epoch:  291\n",
      "291 -------- 0.014872078 3.011361 100.0\n",
      "Saving model at 291 epoch.\n",
      "epoch:  292\n",
      "292 -------- 0.047747582 3.0033388 99.51171875\n",
      "Saving model at 292 epoch.\n",
      "epoch:  293\n",
      "293 -------- 0.02833185 3.4486334 99.70703125\n",
      "Saving model at 293 epoch.\n",
      "epoch:  294\n",
      "294 -------- 0.023042936 3.21602 100.0\n",
      "Saving model at 294 epoch.\n",
      "epoch:  295\n",
      "295 -------- 0.19777979 3.1034868 74.90234375\n",
      "Saving model at 295 epoch.\n",
      "epoch:  296\n",
      "296 -------- 0.037435114 2.7889404 100.0\n",
      "Saving model at 296 epoch.\n",
      "epoch:  297\n",
      "297 -------- 0.03897382 3.3787518 99.0234375\n",
      "Saving model at 297 epoch.\n",
      "epoch:  298\n",
      "298 -------- 0.041474115 3.6285865 98.92578125\n",
      "Saving model at 298 epoch.\n",
      "epoch:  299\n",
      "299 -------- 0.019437237 3.3794343 99.90234375\n",
      "Saving model at 299 epoch.\n",
      "Training finished...\n",
      "Models Saved!\n",
      "--- Time taken to train : 4.0 hours ---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    gan = CycleGAN()\n",
    "    print(\"Training..\")\n",
    "    gan.train(epochs=300, batch_size=1, sample_interval=500)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time)//3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IHnnFbrvlYY2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "train_cyclegan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
